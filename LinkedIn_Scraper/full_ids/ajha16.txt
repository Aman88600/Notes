t-black--light	artdeco-button__text	artdeco-button__text (2)	pvs-header__title	EgGGwITsUmGQhLgXdzztfuzStxvFQFnnCboWrzk (3)	visually-hidden (2)	display-flex	visually-hidden (3)	display-flex (2)	visually-hidden (4)	optional-action-target-wrapper href	optional-action-target-wrapper href (2)	ivm-view-attr__img--centered src	visually-hidden (5)	optional-action-target-wrapper href (3)	visually-hidden (6)	optional-action-target-wrapper href (4)	ivm-view-attr__img--centered src (2)	EgGGwITsUmGQhLgXdzztfuzStxvFQFnnCboWrzk (4)	visually-hidden (7)	EgGGwITsUmGQhLgXdzztfuzStxvFQFnnCboWrzk (5)	visually-hidden (8)	EgGGwITsUmGQhLgXdzztfuzStxvFQFnnCboWrzk (6)	visually-hidden (9)	pvs-entity__caption-wrapper	ivm-view-attr__img--centered src (3)	ivm-view-attr__img--centered src (4)	visually-hidden (11)	visually-hidden (12)	visually-hidden (13)	visually-hidden (14)	ivm-view-attr__img--centered src (5)	visually-hidden (15)	t-14	t-14 (2)	hoverable-link-text	optional-action-target-wrapper href (5)	display-flex (3)	t-14 (3)	pvs-entity__caption-wrapper (2)	optional-action-target-wrapper href (6)	hoverable-link-text (2)	optional-action-target-wrapper href (7)	optional-action-target-wrapper href (8)	t-14 (5)	optional-action-target-wrapper href (19)	pvs-navigation__text	artdeco-tab	artdeco-tab (2)
500+ connections	Follow	Message																																														
			About	"I build AI systems that make sense.
Currently, I’m a Senior Data Scientist at Delta Air Lines, working on Generative AI, NLP, and Causal Inference to solve real-world problems at scale. With a background in Machine Learning, Explainable AI, and C++, I specialize in creating AI models that are not just powerful but also interpretable and actionable.

Beyond my role at Delta, I’m also building PivotAI, an initiative focused on AI-driven innovation. Previously, I worked at Deutsche Telekom, where I tackled complex ML challenges, optimizing large-scale AI applications.

What I do best:
✔️ Generative AI & NLP – Building language models that drive efficiency and automation.
✔️ Causal Inference & Explainable AI – Making AI systems transparent and interpretable.
✔️ Scalable Machine Learning – Applying ML at scale, from research to production.
✔️ High-Performance Computing (C++) – Optimizing AI models for speed and efficiency.

I’m always interested in cutting-edge AI research, solving high-impact problems, and collaborating with like-minded people. If you're working on something cool in AI, let’s connect.

#MachineLearning #GenerativeAI #NLP #CausalInference #ExplainableAI #DataScience #AIInnovation"	I build AI systems that make sense. Currently, I’m a Senior Data Scientist at Delta Air Lines, working on Generative AI, NLP, and Causal Inference to solve real-world problems at scale. With a background in Machine Learning, Explainable AI, and C++, I specialize in creating AI models that are not just powerful but also interpretable and actionable. Beyond my role at Delta, I’m also building PivotAI, an initiative focused on AI-driven innovation. Previously, I worked at Deutsche Telekom, where I tackled complex ML challenges, optimizing large-scale AI applications. What I do best: ✔️ Generative AI & NLP – Building language models that drive efficiency and automation. ✔️ Causal Inference & Explainable AI – Making AI systems transparent and interpretable. ✔️ Scalable Machine Learning – Applying ML at scale, from research to production. ✔️ High-Performance Computing (C++) – Optimizing AI models for speed and efficiency. I’m always interested in cutting-edge AI research, solving high-impact problems, and collaborating with like-minded people. If you're working on something cool in AI, let’s connect. #MachineLearning #GenerativeAI #NLP #CausalInference #ExplainableAI #DataScience #AIInnovation	Top skills	Top skills	Data Science • Natural Language Processing (NLP) • Machine Learning • Deep Learning • Large Language Models (LLM)	Data Science • Natural Language Processing (NLP) • Machine Learning • Deep Learning • Large Language Models (LLM)	https://www.linkedin.com/in/ajha16/overlay/top-skills-details?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg																																						
			Featured	How my team won the World's largest hackathon. Revealed.	Article		How my team won the World's largest hackathon. Revealed.		Ankit Jha (Data Scientist) on LinkedIn	https://www.linkedin.com/pulse/how-my-team-won-worlds-largest-hackathon-revealed-ankit-jha	https://www.linkedin.com/pulse/how-my-team-won-worlds-largest-hackathon-revealed-ankit-jha	https://media.licdn.com/dms/image/v2/C5112AQFngiECUoMxMA/article-cover_image-shrink_423_752/article-cover_image-shrink_423_752/0/1553952051907?e=1762387200&v=beta&t=qv8OERIhIN7FNeEN_sqEZk3NIkO492W4mV7GHydddfM	"My college is in the middle of nowhere in the old heritage city of Bhubaneshwar. We're a little concrete structure full of enthusiastic young minds working relentlessly on daily assignments and placement entrance sample papers, burning the midnight oil in securing the maximum speed on a tacky Wi-Fi connection, messaging our nearest biruyaniwala to add extra spices for the same old price. So it came off as a surprise when someone came up with the idea of participating in hackathons. And participate we did. After intense internal pledges, club formations, massive incentivisations and a bunch of teachers changing our lab wallpapers to some hackathon posters, 2 of our teams won hackathons of national repute. A sum total of 8 out of some 8,000 people had shown interest in taking part with fruitful results. If you'd have asked any teacher about it, they'd have been the proudest heroes. And it was justified. We all were proud. It was not until my friend Subhrajit bagged a big size of the podium in ITC's well known hackathon that I had decided ""Enough! Let me jump in here"". On 13th January 2019, 6 students of Institute of Technical Education and Research, Bhubaneshwar made a team to take over a quarter million others in the Smart India hackathon. But upon learning that this hackathon was supposed to be a programming competition and the largest one in the world, 5 of them walked away. So on the next day, I approached Sandeep, my favourite web developer and we strategized our team formation. Sandeep and I had an experience of 2 and 1 hackathons respectively. But we knew this one was going to be a exasperating cascade of so many factors against us. We had never been to a 24 hour hackathon. We needed fit people who could stay awake for 36 hours. We had our mid semester exams coming up. In case we got selected, we'd have little to no time to design our product's workflow and components (It was allowed in the rule-book). We needed some very very good developers. 300 teams were taking part from our college, a quarter million people were taking part from all over India. We needed serious marketing skills to sell our idea. We knew zero people who had ever qualified in this hackathon. We had to do everything from scratch. So I decided to add 4 people in our team to fill all 4 caveats. Here is our team constitution. I'll let you see through the idea behind selecting each member. Subham- An android developer, also an avid gamer. His focus on strategy and quality was tremendously useful. He also happened to have a cousin who was a star hackathon participant and provided us some valuable feedback. Anupriya- The female programmer. She has been an artist for as long as she has experienced growing up. She was responsible for looking after our designs and how everything looked. Alok- Another gamer, web developer, android beginner, etc. He was the support system, fixing bugs, kept us all up, etc. We had chosen him because he has the ability to mechanically work on anything for longer than most of us. Shikhar- This guy had scaled a product to national level, leveraged marketing skills to build a market of potentially thousands of people and represented India in an international conference. Sandeep- Our web developer, android aficionado and a very trustworthy programmer. His Javascript skills are impeccable. Ankit (Me)- I had a little experience in marketing, event copy-writing, product presentation. I also happen to have worked with machine learning, web penetration testing and I know a few things about this and that. Now that we had half a dozen bad-asses ready to plunder the riches, we set foot on a voyage that changed everything. We met 3 times and discussed our ideas over and over again- correcting everything and adding features that had sounded catchy and subtracting things that didn't make sense. Here were the key points we had focused on- Would we buy the idea if it were a product? If we would, how many times would we interact with it on a daily basis? How much benefit would it yield per unit time? How easy it would be to explain the idea to my grandma who's never used a smartphone. I call this rubber duck presentation- present your idea to a toy and you figure out things you should add / remove. How drunk would a judge have to be to give us the winning trophy. I call it the drunk judge problem. If your drunk judge index is less than 5, you are good to go. A user stumbles upon our app. How does he navigate his / her way through. What buttons he / she needs to click. What would be his / her reaction. We designed flow charts for everything. Next we decided on the most catchy words and colours to be added to our presentation. Remember we had to stand out. Standing out of a quarter million presentations is a tough job. Our team unanimously agreed to use Google docs to make our presentation. Slidemodel is a great resource where you can find great templates for Google docs presentation for free. We also used GIMP and Photoshop to enhance the User Experience of the presentation that we were supposed to send. Here's a look at a presentation that we had sent. Please do not copy this idea. It was not selected. Our final presentation was different from this. Not very much but still. The format was given by the organisers. We had presented only minor improvements to their prescription. The focus of our presentation and description was - It should explain the idea very very clearly It should have mild colours. According to colour theory red is too aggressive and blue is too cold and mild, we needed to use more light green, grey and yellow. The tech stack should look realistic for people who know but for people who don't- it should still sound familiar. So we used logos prominently. The words we use should sound very professional. I used Google's Adwords tools to find most commonly searched words and put them together. All our 3 presentations were approved by our college which was also our SPOC (All were in student innovation category which is a category open to every kind of idea. The only downside is- it has 30 times more participation than any non innovation focused idea) Snap snap! Back to reality. We went back expecting no good news. After all history repeats itself and Murphy's law holds tight. Right? Fortunately, that didn't happen this particular time. After 3 years, finally one team qualified from our university. 2 out of 3 submitted ideas were accepted. Three cheers for team Leetcoders. I have always been a reader of Leo Tolstoy and the Anna Karenina principle has been something that has driven all my decisions up until now. For those of you who have not stumbled upon this yet, here's a quote from Wikipedia In statistics, the term Anna Karenina principle is used to describe significance tests: there are any number of ways in which a dataset may violate the null hypothesis and only one in which all the assumptions are satisfied. The things that could violate our null hypothesis were as follows- We didn't have money to go to Kharagpur (which was our nodal centre), buy shirts, banners and standees. (Yeah, you need to buy all this yourself) We didn't have any mentor, experience or idea about what we were getting ourselves into. Our team constituted of less programmers and our programmers were not congruent on one tech stack that we could have worked on unanimously. We had our mid semester exams approaching and none of us were ready for it. So here's what we did. Sandeep taught me basics of the MERN stack and suggested studying Wes Bos. So I finished React for beginners in the next 20 hours. ( I highly recommend that course). Then a few of our team members were instructed to go through FreeCodeCamp's course on Javascript. I learned socket.io, pusher and a lot of other technologies in that time frame. Subham was told to start working on a wire-frame and a workflow for his application- all while we were also attending our exams. We leveraged a lot of contacts and wrote a very concise letter to our college which fetched us Rs 26,200 as total funding. I recommend reading How to write anything by Laura Brown. The book helped immensely in our efforts to secure funding for the mammoth that on our dinner table. The easy part was travelling from one end of the city to the other, finding textile mills that were ready to deliver within 3-4 day and getting our shirts designed. In the next 3 days we had every single thing sorted out- right from the tickets to the documents. We found a list of faculties in our college, sifted through faculties that had joined recently (implied young faculty members) and found one who had graduated from IIT Kharagpur. We then approached him with our idea and it looked like he was satisfied with our pitch. We then wrote another letter to the college requesting them to allow Nitesh Sir to be our mentor and after a few letters here and a few there, he was officially on board as the 7th member of the team. I say it like that because he was the one who kept us cool throughout the competition which lead to our victory. I was planing to skip my mid sems but then I could somehow pull off 22 hour days and 2 hours of sleep didn't appear bad. After 10 days of this, I did reward myself with 13 hours of sleep before we left for the voyage. If I can, you can. Because all my team did too. The night before our departure, Sandeep and I decided to design a flow of how things would work out. We wrote down the whole schedule on paper and based on how much productive each member would have been at what time, we designed a complete proceeding of how things should have panned out for us. A personal body clock itinerary. When I say everything, I mean EVERY single little detail ranging from who will brush his teeth and who will eat food. By evening time, team Leetcoders was officially in IIT Kharagpur. By night time, we were done with our registrations, officially. Here are 4 things you should make sure when you reach your nodal centre- Charge your phones, laptops and power banks. Make sure they are at maximum possible battery level. Carry caffeine tablets, Redbull or anything that keeps you awake. Most nodal centres are in rural areas and you won't get Redbull from team SIH. At least we didn't. Carry a notepad with a rough sketch of your plan of action. Also create a group chat on something simple like tlk.io or connect with each other on Pushbullet in order to facilitate link sharing and local file transfers without lag. Carry a paper with each other's phone and computer passwords and phone numbers. Use a temporary password on your device for the given duration. In case if your team member is away or your phone runs out of power, you can use this guide to get around the problem. I assume that you have little to no interest in any more tips so I'll narrate the whole thing like a story. I didn't find any detailed experience blogs for this particular event on the internet so let this one be the ubiquitous blog- the one and only one guide to everything SIH. So like everywhere in India, men and women were kept in different hostels. We were separated from Anupriya- 3 of us in one room and 2 in another. Our mentor Nitesh sir was in his own room chilling with other mentors. That night we looked at all the teams we were competing against. We searched all the captains on Linkedin and Github and looked at their project set, we even found some teams who had already prepared their projects. That was disheartening since it should have been counted against them but I digress. We looked at every single thing that could have given us any hints about their ideas and made notes about it. We collected points that could have resulted in us losing and made improvements in our idea. It had already been 2 AM. It was time to sleep. Hackthon begun at 6. We checked our bags, tested our standees and flexes and dozed off. The 5 boys of team leetcoders jogged their way to the bus parking from the hostel early on next morning. The game was on. Our first problem came when my Linux PC couldn't connect to the Wi-Fi because I didn't know how to manually tunnel it through a TLS connection and set up a custom user. I however worked around it with my mentor and it circumvented the problem for good. The only problem was- it took an hour off my schedule. Meanwhile, Sandeep's React components were not working and Anupriya's laptop failed to run the bootstrap scripts that were running on my machine. Subham's Firebase uploads were resulting in a crash and Shikhar and Alok were not able to find participants for the survey. (We were conducting a survey to implore the validity of our idea and present our perspective in a data-first format). We had decided to show stages of our project with a live development timeline on Powerpoint presentations and live survey stats. Our first judgement went really bad. It made some of our eyes moist. It it would continue like that, we'd definitely lose the competition by a margin we'd never understand. Our project was obviously not selected to be shown to the Prime Minister and that obviously didn't help our self confidences. But team leetcoders is a strong team and we didn't prove to by anything otherwise. That night, I could successfully train my R-CNNs, we ported the React code to common HTML and it began working. By 6 in the morning we were ready with a prototype that worked unbelievably well. Till 10 in the morning, a famous Bollywood singer's team had seen our survey and they shared it on her Instagram page with millions of followers. That lead to an influx of survey results in thousands. Just before the first presentation our Android application started working as well. Our second presentation was so good, it was a stark contrast to the first one. But the most challenging aspect of our project was- scale. Sandeep and I ported the code to our cloud. Meanwhile the team prepared the landing page to include all componenets of the project. (Pro Tip- use c9 if you don't know AWS and you just need to deploy some small hackathon script). The part failed more than once and it again looked like we were going to lose it. Then it suddenly started working and we still don't know how that happened. We also had to show the offline functionality of our project which was easy. We hosted the whole thing on Chrome server (it's an app on the chrome web store) and everything was in order for the final presentation. Shikhar and I sat down for the presentation, collecting reports from the survey. 2 hours before the final presentation there was a mentor's talk and the mentor wasn't very pleased with our idea so we asked him why. We made notes of all his comments and implemented the hacks in the next 2 hours. We also included a slide that said how our project was different from anything that had ever existed. Lack of sleep had started to take over me and I started getting cranky. (I couldn't sleep at night because I was a little too anxious of our failures in round 1). We had no Redbull to help and I had run out of raw coffee that I always carry so Alok got me a Coca Cola from the nearest shop. Our final presentation was the best thing that happened in those 36 hours. Oddly satisfying. It was time for top 6 announcement. I was asleep. I can't write suspense stories and you probably already know the results. My mentor woke me up, Alok ran for another coke and we rephrased our presentation. We entered the room- The power ran out, the projector crashed and the pen drive got the shortcut malware. The judges had to wait for 10 minutes for anything to start. But I held tight. I didn't get cranky and my team kept them engaged in conversation about everything. Fast forward- 30 minutes later. Result time. We had emerged the second runners up. Here are 5 things I learned and you can immediately employ in your next hackathon- Code quality and documentation do help but the judges don't care about it a lot. Most judges are not very very well versed with everything you are doing. So you can use the trade off to your advantage Features that look beautiful are features that look useful. The halo effect stands strong with this one. We prepared presentations for every single round of evaluation. We had one person dedicated to this. This particular person was either Alok or Shikhar at any given point. They trained in Photoshop and Google docs specially for this. Every team member had a department they were entrusted with. Every team member also had a fallback department so everyone served a dual purpose on the team. Our main focus was on letting the judges use the product for themselves and seeing what happens next. Since our product also involved syncing of 10s of computers and an android application, it resulted in much higher impact in the last round. I hope this guide helps you win the Smart India Hackathon 2020. We need more conquerors in this world. All the best Ankit"	https://www.linkedin.com/pulse/how-become-machine-learning-legend-3-minutes-56-seconds-ankit-jha	Article	https://www.linkedin.com/pulse/how-become-machine-learning-legend-3-minutes-56-seconds-ankit-jha	https://media.licdn.com/dms/image/v2/C5112AQGBTHNgJsjOQg/article-cover_image-shrink_423_752/article-cover_image-shrink_423_752/0/1563137559224?e=1762387200&v=beta&t=i2qLcC02jRS0B2tHAMCvoc-nSnDl10fl-zFX4D1Rivs	How to become a Machine Learning legend in 3 minutes and 56 seconds.	How to become a Machine Learning legend in 3 minutes and 56 seconds.	Ankit Jha (Data Scientist) on LinkedIn	Ankit Jha (Data Scientist) on LinkedIn	"Every single day, my Instagram is filled with advertisements of people trying to teach me Machine Learning. It seems as if the universe has conspired to teach us software engineering enthusiasts about the ins and outs of applied statistics before a super intelligent robot is announced our supreme leader. A lot of people would have a tough time realising that Tensorflow- the most popular machine learning library was released only in Novemeber 2015. And with it's release it eliminated the elitism associated with machine learning - at least on the surface in terms of rapid prototyping of ideas. Machine learning as an academic discipline precedes the frameworks by at least half a century. Kaggle, for example has been here for about 10 years. But Tensorflow and Keras have brought along a culture of ""get rich quick"" schemes. Several dudes who learned a few things and could develop a few cool projects (thanks to the abstraction presented by modern ML frameworks) have jumped into the teaching business. And the worst thing is, they are all making money by selling the same courses in different packages and prices. Most online tutors who teach anything at all have at least one course on Machine learning and some of them became overnight millionaires without buying Bitcoins When I started with penetration testing and ethical hacking in high school, I had faced similar dilemmas. 17 year old kids who couldn't change directories on Linux systems were teaching WiFi hacking inside corporate offices and making mad money. And with so many people working so hard to adapt to the markets, all of these teacher had customers. Machine learning is not simple. Far from it, it is one of the most complex and blissful subjects in human history. It's so pristine and has such a wide learning curve that anyone who knows anything can participate in the advancements in this domain. Any data helps. But all of us who volunteer to get in need to stay wary of Godmen who've never read a single research paper. We need to stop giving our money to them and do our own research. We need to appreciate the complexities the subject brings. Buying machine learning course is like buying water from a 5 star hotel when you can easily get it for free from any public tap. Here's how to learn Machine learning for free I'm an absolute beginner. Trust me. So if you've any degree of experience, you may decide to not follow my path. It worked for me. It might not work for you. Before starting Machine Learning, I had some idea in following domains- Calculus- Differentiation, Integration, Differential equation, optimisation. Algebra- Matrix operations Trigonometry Kinematics, thermodynamics, optics and elementary physics If you do not have some basic idea bout these subjects, I highly recommend reading Ron Larson's books. For kinematics- Pradeep Kshetrapal sir has some very good videos on YouTube. But that's not it. I realised that if you want to read through Machine learning papers you need to be really confident with your calculus and algebra. Here's how you can do that. Read through Gilbert Strang's books. You can also follow his video lectures on YouTube but they are very lengthy. I'd rather recommend Khan Academy's videos on the same subject. You really want to get a good command on subjects like SVD decomposition, LRU decomposition, convolution and so on. Fast.ai has some good resources on this on their Github but it could be a little tacky for a beginner so starting with a code first approach in this area isn't my advice. (I'm still trying to wrap my head around a lot of those courses) For calculus, I solved through J Stewart as a part of my coursework. You really want to get good at topics like differentiation, partial differentiation and integration. You may or may not skip Differential equation based on your interest level. Khan Academy's calculus is really good if we're talking about video courses but I recommend following a proper book for the purpose. Get some idea about graphs, trees and other data structures. You will need them all the time. A good resources to learn them is to read Steven Skiena's book on Algorithms. If it's a little overwhelming in the beginning, you can Get some very strong idea about what optimisation (convex optimisation) is and what it intuitively does. Any article or lecture on YouTube should suffice. Now that you have your fundamentals taken care of, it's time to move in to the deeper stuff. A lot of machine learning is just applied statistics. The most naive machine learning algorithm (Simple Linear Regression) is a very elementary mathematical assumption that comes from statistics. (For example, if 3 cows give 6 buckets of milk, how many cows will we need for 8 buckets of milk). In fact, the idea behind any regression is- ""how much better prediction can we make than calculating the average of what we already have"". So in order to understand Machine Learning, we need to understand statistics. Here are some subjects that I think are absolutely essential- Probability theory and the Bayes theorem. Various data distributions- the normal distribution, the t- distribution, the f- distribution, etc. Also concepts like Maximum Likelihood Estimator, Parametric and non parametric statistics Hypothesis testing Exploratory Data Analysis- the concept of creating, reading and understanding various different types of graphs and data representations. Here are a few resources that you might find useful here- Stepik- a popular learning app has a free statistics course which is probably the best start you can ever get. The breakdown and the course structure is amazing. Next, Think Stats and the Think Bayes book. These very popular books are both free and make a lot of sense. Once you read them (even if you don't code along), you'll feel very very good about your fundamentals. They are a good primer for Bayes theorem Brilliant.org has some very good articles about concepts like Maximum Likelihood estimator and hypothesis testing. Statsbyjim is a popular blog by someone called Jim. His articles on hypothesis testing can be a great resource about hypothesis testing. This handbook is a great resource for learning about exploratory data analysis. Once you are done with this- you can head over to Datacamp (you can get a free 3 month trial with Microsoft developer essentials) and practice your graph plotting skills using matplotlib and ggplot2. Reddits dataisbeautiful is a good resource to look at some exemplary EDA projects. Alright so now that you can draw graphs and you can understand algorithms and read papers, you need to start learning some real machine learning. But before you do that you need to understand that you can't always stay there reading and making notes. You will have to follow at least one programming language in order to study and implement your algorithms and models. An obvious choice is Python because everyone else is doing Python but you have other tools in your arsenal like- R- R's Tidyverse has great resources to plot very beautiful graphs. In fact, ggplot2- the most popular graph making library is from R Tableau- A good Graphical User Interface which can come handy if you want a quick data analysis done. WEKA is a very basic tool that can help you visualise how algorithms work on your data. If scikit learn and Tensorflow are like Adobe Photoshop, WEKA is the MS Paint of Machine Learning. SPSS by IBM- a vast library of Machine Learning algorithms to do some quick tasks. Javascript- If you're trying to deploy machine learning on your web page you can use Javascript. Even in exploratory analysis D3.js is a great resource to get going. I'm assuming that you have some good idea of Python but if you don't- I'd recommend reading through this book called- ' Automate The Boring Stuff'- It's available as a free website or a paid Udemy course, whatever you prefer.+ Before you start off with ML, I recommend going through these tools- Jupyter- a notebook for better and structured presentation of your ML project. To get started install anaconda Python on your device. You can watch Corey Schafer's video on YouTube to learn almost everything about Jupyter. These notebooks are borrowed from IPython notebooks. You might also want to get familiar with Spyder the popular Python IDE in order to work your way through. Knowing a little bit of Linux doesn't harm Try getting your hands dirty with Google Collab. They offer a great GPU accelerated computer for free to train your ML algorithms. Now that you are done with all of this, it's time to get acquainted to few popular Python ML libraries. Numpy- Numerical Python. It is a very basic mathematical library. A great resource to learn about it is Tutorialspoint. Scipy- for a few popular scientific algorithms. I don't think learning scipy specifically is important at this stage. Statsmodels - This library contains a lot of statistical tools and formulas for working on statistical algorithms. Matplotlib- Great resource to plot graphs. Datacamp is a great resource. Scikitlearn- Th e very popular statistical algorithm library Theano- Skip it. Learn Tensorflow Tensorflow- read the official documentation even if you don't understand it. Keras- You've already learned this if you've been working with Tensorflow. PyTorch- Python port of popular Lua library called Torch. You may or may not learn this instead of Tensorflow. You can learn both but PyTorch is more often used in research than in popoular projects so decide what suits you. They both are equally good. OpenCV / cv2- A great resource that contains a lot of fast paced and optimised computer vision algorithms. Now that you have your tools and your toolbox, here's how I'd recommend learning it all. Linear Regression- start with Andrew Ng then read ISL (free book, look for Introduction to statistical Learning pdf free) Logistic Regression- Same pattern as above. If you don't however understand the concept, go ahead and read blogs on this. This particular concept is difficult You can follow this up by reading the next chapters (skip dimensionality reduction) from ISL (Skip Linear Algebra and Octave from Andrew Ng) up to decision trees and can skip all of Andrew Ng's lectures on them You can then read Machine learning system design by Andrew Ng (Skip Neural networks for the time) Study SVM by ISL, then listen to Andrew Ng followed by a lecture by sir Patrick Winston and then Yuship Bengio. If you still don't understand search for a popular paper on Support Vector Regression and read through Skim through unsupervised learning and you're done with both the book. You should also listen to Andrew Ng speaking on those subjects. Now go back to Welsch Labs on YouTube and watch their video series on Neural Networks. Follow it up with 3Blue1Brown's Neural network series and move on to Andrew Ng's deeplearning.ai course for the same. Download and print Efficient back-propagation by YannLeCunn and read through the whole thing and implement your first project while reading through neuralnetworksanddeeplearning's course Learn more about images. Finish the part 1 and 2 of Image Processing by Duke University (Image and Video Processing: From Mars to Hollywood with a Stop at the Hospital) Start off with Andrew Ng for CNN and follow it up with CS231n's videos. Don't forget to read Yann LeCun's paper on CNN. That dude literally made CNNs. If you find time read through all papers from simple CNN to YOLO2 (There must be a timeline somewhere on the web). Before starting off with RNN, please finish through the NLTK book to understand how computers understand text. Start off with Andrew Ng for RNN and follow it up with Andrej Karpathy's blogs and lectures about the same. Read the famous blog on LSTM and watch important lectures of CS224d. (After Midsem syllabus) Now start reading through Ian Goodfellow's book called Deeplearningbook and finish part 1 and part 2 Go back and listen to Geoffery Hinton speak about other these things in his course on Neural Networks for Machine Learning. Read Ian's book part 3 Read Ian's paper on GANs and read through These papers Now go back to Udemy for Kirill Eremenko and implement all algorithms you learned at least once (This part is paid but it is generally cheap and worth it). (ML a to z, DL A to Z and computer vision A to Z) Learn about analysing Time series data Learn Flask and Django to understand how to deploy algorithms in case you're making software. Now go back and listen to professor Deepak Khemani's lectures on Artificial Intelligence and how important algorithms can be used. You can find the implementation on a book called IAML by Russell and Norvig. IAML takes part in Google Summer of Code every year and they have their updated Github repo with all these algorithms implemented from scratch . Do that Read through Multi Arm Bandit problems Here Now learn about OpenAI Gym and start CS294-112 from Berkeley. This will give you a lot of idea about Deep Reinforcement Learning Go through Nature of Code github repository and implement several algorithms upto Neurovolution. The accompanying videos by The Coding Train should be really helpful Listen to MIT's AGI series by Lex Fridman Go through course 7 (Big data example) and course 2 (How to Kaggle) on Advance ML specialisation on Coursera Congratulations! You are a machine learning beginner now. This whole process should take anywhere from 2.5 to 3 years to complete effectively given that you put in 2-3 hours every day. If not, it can take longer. Courses you can do after this are- Convex Optimization by Boyd on Standford Advance Linear models for data scientists Game Thory 101 on YouTube Knowledge based AI by Georgia Tech Theory of Mind and related metaphysical aspects of AI (Follow Ned Block's page) I think this resource might help you in becoming a Machine Learning legend. Please take your time. Please don't get tired. Good luck! See you on the next one."	"Every single day, my Instagram is filled with advertisements of people trying to teach me Machine Learning. It seems as if the universe has conspired to teach us software engineering enthusiasts about the ins and outs of applied statistics before a super intelligent robot is announced our supreme leader. A lot of people would have a tough time realising that Tensorflow- the most popular machine learning library was released only in Novemeber 2015. And with it's release it eliminated the elitism associated with machine learning - at least on the surface in terms of rapid prototyping of ideas. Machine learning as an academic discipline precedes the frameworks by at least half a century. Kaggle, for example has been here for about 10 years. But Tensorflow and Keras have brought along a culture of ""get rich quick"" schemes. Several dudes who learned a few things and could develop a few cool projects (thanks to the abstraction presented by modern ML frameworks) have jumped into the teaching business. And the worst thing is, they are all making money by selling the same courses in different packages and prices. Most online tutors who teach anything at all have at least one course on Machine learning and some of them became overnight millionaires without buying Bitcoins When I started with penetration testing and ethical hacking in high school, I had faced similar dilemmas. 17 year old kids who couldn't change directories on Linux systems were teaching WiFi hacking inside corporate offices and making mad money. And with so many people working so hard to adapt to the markets, all of these teacher had customers. Machine learning is not simple. Far from it, it is one of the most complex and blissful subjects in human history. It's so pristine and has such a wide learning curve that anyone who knows anything can participate in the advancements in this domain. Any data helps. But all of us who volunteer to get in need to stay wary of Godmen who've never read a single research paper. We need to stop giving our money to them and do our own research. We need to appreciate the complexities the subject brings. Buying machine learning course is like buying water from a 5 star hotel when you can easily get it for free from any public tap. Here's how to learn Machine learning for free I'm an absolute beginner. Trust me. So if you've any degree of experience, you may decide to not follow my path. It worked for me. It might not work for you. Before starting Machine Learning, I had some idea in following domains- Calculus- Differentiation, Integration, Differential equation, optimisation. Algebra- Matrix operations Trigonometry Kinematics, thermodynamics, optics and elementary physics If you do not have some basic idea bout these subjects, I highly recommend reading Ron Larson's books. For kinematics- Pradeep Kshetrapal sir has some very good videos on YouTube. But that's not it. I realised that if you want to read through Machine learning papers you need to be really confident with your calculus and algebra. Here's how you can do that. Read through Gilbert Strang's books. You can also follow his video lectures on YouTube but they are very lengthy. I'd rather recommend Khan Academy's videos on the same subject. You really want to get a good command on subjects like SVD decomposition, LRU decomposition, convolution and so on. Fast.ai has some good resources on this on their Github but it could be a little tacky for a beginner so starting with a code first approach in this area isn't my advice. (I'm still trying to wrap my head around a lot of those courses) For calculus, I solved through J Stewart as a part of my coursework. You really want to get good at topics like differentiation, partial differentiation and integration. You may or may not skip Differential equation based on your interest level. Khan Academy's calculus is really good if we're talking about video courses but I recommend following a proper book for the purpose. Get some idea about graphs, trees and other data structures. You will need them all the time. A good resources to learn them is to read Steven Skiena's book on Algorithms. If it's a little overwhelming in the beginning, you can Get some very strong idea about what optimisation (convex optimisation) is and what it intuitively does. Any article or lecture on YouTube should suffice. Now that you have your fundamentals taken care of, it's time to move in to the deeper stuff. A lot of machine learning is just applied statistics. The most naive machine learning algorithm (Simple Linear Regression) is a very elementary mathematical assumption that comes from statistics. (For example, if 3 cows give 6 buckets of milk, how many cows will we need for 8 buckets of milk). In fact, the idea behind any regression is- ""how much better prediction can we make than calculating the average of what we already have"". So in order to understand Machine Learning, we need to understand statistics. Here are some subjects that I think are absolutely essential- Probability theory and the Bayes theorem. Various data distributions- the normal distribution, the t- distribution, the f- distribution, etc. Also concepts like Maximum Likelihood Estimator, Parametric and non parametric statistics Hypothesis testing Exploratory Data Analysis- the concept of creating, reading and understanding various different types of graphs and data representations. Here are a few resources that you might find useful here- Stepik- a popular learning app has a free statistics course which is probably the best start you can ever get. The breakdown and the course structure is amazing. Next, Think Stats and the Think Bayes book. These very popular books are both free and make a lot of sense. Once you read them (even if you don't code along), you'll feel very very good about your fundamentals. They are a good primer for Bayes theorem Brilliant.org has some very good articles about concepts like Maximum Likelihood estimator and hypothesis testing. Statsbyjim is a popular blog by someone called Jim. His articles on hypothesis testing can be a great resource about hypothesis testing. This handbook is a great resource for learning about exploratory data analysis. Once you are done with this- you can head over to Datacamp (you can get a free 3 month trial with Microsoft developer essentials) and practice your graph plotting skills using matplotlib and ggplot2. Reddits dataisbeautiful is a good resource to look at some exemplary EDA projects. Alright so now that you can draw graphs and you can understand algorithms and read papers, you need to start learning some real machine learning. But before you do that you need to understand that you can't always stay there reading and making notes. You will have to follow at least one programming language in order to study and implement your algorithms and models. An obvious choice is Python because everyone else is doing Python but you have other tools in your arsenal like- R- R's Tidyverse has great resources to plot very beautiful graphs. In fact, ggplot2- the most popular graph making library is from R Tableau- A good Graphical User Interface which can come handy if you want a quick data analysis done. WEKA is a very basic tool that can help you visualise how algorithms work on your data. If scikit learn and Tensorflow are like Adobe Photoshop, WEKA is the MS Paint of Machine Learning. SPSS by IBM- a vast library of Machine Learning algorithms to do some quick tasks. Javascript- If you're trying to deploy machine learning on your web page you can use Javascript. Even in exploratory analysis D3.js is a great resource to get going. I'm assuming that you have some good idea of Python but if you don't- I'd recommend reading through this book called- ' Automate The Boring Stuff'- It's available as a free website or a paid Udemy course, whatever you prefer.+ Before you start off with ML, I recommend going through these tools- Jupyter- a notebook for better and structured presentation of your ML project. To get started install anaconda Python on your device. You can watch Corey Schafer's video on YouTube to learn almost everything about Jupyter. These notebooks are borrowed from IPython notebooks. You might also want to get familiar with Spyder the popular Python IDE in order to work your way through. Knowing a little bit of Linux doesn't harm Try getting your hands dirty with Google Collab. They offer a great GPU accelerated computer for free to train your ML algorithms. Now that you are done with all of this, it's time to get acquainted to few popular Python ML libraries. Numpy- Numerical Python. It is a very basic mathematical library. A great resource to learn about it is Tutorialspoint. Scipy- for a few popular scientific algorithms. I don't think learning scipy specifically is important at this stage. Statsmodels - This library contains a lot of statistical tools and formulas for working on statistical algorithms. Matplotlib- Great resource to plot graphs. Datacamp is a great resource. Scikitlearn- Th e very popular statistical algorithm library Theano- Skip it. Learn Tensorflow Tensorflow- read the official documentation even if you don't understand it. Keras- You've already learned this if you've been working with Tensorflow. PyTorch- Python port of popular Lua library called Torch. You may or may not learn this instead of Tensorflow. You can learn both but PyTorch is more often used in research than in popoular projects so decide what suits you. They both are equally good. OpenCV / cv2- A great resource that contains a lot of fast paced and optimised computer vision algorithms. Now that you have your tools and your toolbox, here's how I'd recommend learning it all. Linear Regression- start with Andrew Ng then read ISL (free book, look for Introduction to statistical Learning pdf free) Logistic Regression- Same pattern as above. If you don't however understand the concept, go ahead and read blogs on this. This particular concept is difficult You can follow this up by reading the next chapters (skip dimensionality reduction) from ISL (Skip Linear Algebra and Octave from Andrew Ng) up to decision trees and can skip all of Andrew Ng's lectures on them You can then read Machine learning system design by Andrew Ng (Skip Neural networks for the time) Study SVM by ISL, then listen to Andrew Ng followed by a lecture by sir Patrick Winston and then Yuship Bengio. If you still don't understand search for a popular paper on Support Vector Regression and read through Skim through unsupervised learning and you're done with both the book. You should also listen to Andrew Ng speaking on those subjects. Now go back to Welsch Labs on YouTube and watch their video series on Neural Networks. Follow it up with 3Blue1Brown's Neural network series and move on to Andrew Ng's deeplearning.ai course for the same. Download and print Efficient back-propagation by YannLeCunn and read through the whole thing and implement your first project while reading through neuralnetworksanddeeplearning's course Learn more about images. Finish the part 1 and 2 of Image Processing by Duke University (Image and Video Processing: From Mars to Hollywood with a Stop at the Hospital) Start off with Andrew Ng for CNN and follow it up with CS231n's videos. Don't forget to read Yann LeCun's paper on CNN. That dude literally made CNNs. If you find time read through all papers from simple CNN to YOLO2 (There must be a timeline somewhere on the web). Before starting off with RNN, please finish through the NLTK book to understand how computers understand text. Start off with Andrew Ng for RNN and follow it up with Andrej Karpathy's blogs and lectures about the same. Read the famous blog on LSTM and watch important lectures of CS224d. (After Midsem syllabus) Now start reading through Ian Goodfellow's book called Deeplearningbook and finish part 1 and part 2 Go back and listen to Geoffery Hinton speak about other these things in his course on Neural Networks for Machine Learning. Read Ian's book part 3 Read Ian's paper on GANs and read through These papers Now go back to Udemy for Kirill Eremenko and implement all algorithms you learned at least once (This part is paid but it is generally cheap and worth it). (ML a to z, DL A to Z and computer vision A to Z) Learn about analysing Time series data Learn Flask and Django to understand how to deploy algorithms in case you're making software. Now go back and listen to professor Deepak Khemani's lectures on Artificial Intelligence and how important algorithms can be used. You can find the implementation on a book called IAML by Russell and Norvig. IAML takes part in Google Summer of Code every year and they have their updated Github repo with all these algorithms implemented from scratch . Do that Read through Multi Arm Bandit problems Here Now learn about OpenAI Gym and start CS294-112 from Berkeley. This will give you a lot of idea about Deep Reinforcement Learning Go through Nature of Code github repository and implement several algorithms upto Neurovolution. The accompanying videos by The Coding Train should be really helpful Listen to MIT's AGI series by Lex Fridman Go through course 7 (Big data example) and course 2 (How to Kaggle) on Advance ML specialisation on Coursera Congratulations! You are a machine learning beginner now. This whole process should take anywhere from 2.5 to 3 years to complete effectively given that you put in 2-3 hours every day. If not, it can take longer. Courses you can do after this are- Convex Optimization by Boyd on Standford Advance Linear models for data scientists Game Thory 101 on YouTube Knowledge based AI by Georgia Tech Theory of Mind and related metaphysical aspects of AI (Follow Ned Block's page) I think this resource might help you in becoming a Machine Learning legend. Please take your time. Please don't get tired. Good luck! See you on the next one."																									
7 comments	Follow	Show all posts	Activity		5,215 followers		Ankit Jha (Data Scientist)		Verified • 3rd+			https://media.licdn.com/dms/image/v2/D5603AQH3Ae3LjbUYBg/profile-displayphoto-shrink_100_100/profile-displayphoto-shrink_100_100/0/1732862494864?e=1759363200&v=beta&t=jA3VH4N_mwUaDLcb4KANVA-AZBD4HswlPeYjrKjLuN0	Senior Data Scientist @Delta Air Lines | Founder @PivotAI | Generative AI | Machine Learning | C++ | NLP | IIT Patna | Ex-Deutsche Telekom		5 days ago • Visible to anyone on or off LinkedIn		https://media.licdn.com/dms/image/v2/D5622AQG5DEpPbER_XQ/feedshare-shrink_800/B56ZjmeniaHkAk-/0/1756213452568?e=1759363200&v=beta&t=P6zbK5CNOVhlcmMgW1hLKIO5L0YgI9yTb8i7p2INvcQ		Activate to view larger image,		Activate to view larger image,		Abhishek Jaiswal	5,215 followers	https://media.licdn.com/dms/image/v2/D5603AQH3Ae3LjbUYBg/profile-displayphoto-shrink_100_100/profile-displayphoto-shrink_100_100/0/1732862494864?e=1759363200&v=beta&t=jA3VH4N_mwUaDLcb4KANVA-AZBD4HswlPeYjrKjLuN0	https://media.licdn.com/dms/image/v2/D5603AQHxJpFKyTbppA/profile-displayphoto-shrink_100_100/profile-displayphoto-shrink_100_100/0/1699637869793?e=1759363200&v=beta&t=EopzboCK-xRQWNojPSdSbpFXAdUafsgUltgHwQnQzOs	Verified • 3rd+	Security and AI | BlackHat Speaker | CRED	3 weeks ago • Visible to anyone on or off LinkedIn	Activate to view larger image,	https://media.licdn.com/dms/image/v2/D5622AQGC6ItFkbIkeg/feedshare-shrink_800/B56ZiLR4rCG4Ag-/0/1754683380285?e=1759363200&v=beta&t=Z6sRKW9IRtQOTUVNKwfKxSyIs4bGh0hfl4R2i26ehUA	Activate to view larger image,																
			Experience	"Successfully developed a novel approach to proactively identify potential broadband issues, enabling preemptive interventions and preventing customer dissatisfaction.

Demonstrated expertise in extracting meaningful insights from complex technical data, leading to significant improvements in customer satisfaction and NPS.

Actively collaborate with overseas teams in Germany and across India, fostering a global network of expertise and knowledge exchange while working under Agile Software development practices."	Senior Data Scientist	Senior Data Scientist	Delta Air Lines · Full-time	helped me get this job	Jun 2024 to Present · 1 yr 3 mos	https://www.linkedin.com/company/2272/	https://www.linkedin.com/company/2272/	https://media.licdn.com/dms/image/v2/D4E0BAQEOm_XRWPM8FA/company-logo_100_100/company-logo_100_100/0/1736347498994/delta_air_lines_logo?e=1759363200&v=beta&t=wB1vKq2Csl_QV4XopRUkzdr8WDfjuoN4aS7BmE8_VuM	Bengaluru, Karnataka, India · Hybrid	https://www.linkedin.com/in/ajha16/overlay/urn:li:fsd_profilePosition:(ACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg,2444810760)/skill-associations-details?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg	LinkedIn helped me get this job	https://www.linkedin.com/company/1593/	https://media.licdn.com/dms/image/v2/D4E0BAQEWmXes9VVQNA/company-logo_100_100/company-logo_100_100/0/1722505420199/telekom_logo?e=1759363200&v=beta&t=R0ECnssosYweFEZpAr0AJ-GoO3g-oA3emmVszM2dstc	"Played a vital role in the creation of a novel pipeline that automatically converts raw text into actionable SQL queries, ensuring data quality and alignment with problem descriptions.

Helped in the development of a genetic algorithm-based feature engineering toolkit to generate RFM (Recency, Frequency, Monetary Value) features, enhancing the predictive power of our models.

Crafted an ML toolkit equipped with state-of-the-art extreme classification and clustering algorithms, enabling the solution to tackle complex pharmaceutical data challenges.

Implemented model explainability techniques to provide insights into the decision-making process of our models, fostering transparency and trust in the generated insights.

Successfully ported the AutoML solution to AWS, leveraging its scalability and infrastructure to support large-scale pharmaceutical data analysis.

Utilized Big Data technologies, including Hadoop, PySpark, and SQL, for efficient data processing and analysis.

Mastered Python, Docker, Kubernetes, and deep learning frameworks to build and deploy sophisticated ML models.

Demonstrated a deep understanding of causal inference principles, incorporating them into the AutoML solution to enhance its interpretability and real-world impact."	Data Scientist	Extended my participation in the projects that I began during my internship.	Deutsche Telekom · Full-time	"Utilized deep learning expertise to develop BERT models for text classification, spell correction, and sentence segmentation and alignment which played a pivotal role in bridging the gap between raw process data and actionable instructions, revolutionizing enterprise support operations.

Leveraging BERT-based models, successfully transformed unstructured process logs into structured instructions, streamlining troubleshooting and resolution processes."	Oct 2022 to Jun 2024 · 1 yr 9 mos	Jun 2024 - Present · 1 yr 3 mos	https://media.licdn.com/dms/image/v2/D560BAQHMSLJpNZSfhQ/company-logo_100_100/B56Zh6qM2lHMAU-/0/1754404540294/zs_associates_logo?e=1759363200&v=beta&t=f40UBPoW5XMxtyHvcHlu8MR0pb0rOsXX1Lm0TvpgC54	https://media.licdn.com/dms/image/v2/C560BAQEV9kECiZwXrg/company-logo_100_100/company-logo_100_100/0/1656645409373/informatica_logo?e=1759363200&v=beta&t=_n4-P6zix_Y1eeCK18cq622u5Dfps6t1rLk_vOauEdE	LinkedIn helped me get this job	Successfully developed a novel approach to proactively identify potential broadband issues, enabling preemptive interventions and preventing customer dissatisfaction. Demonstrated expertise in extracting meaningful insights from complex technical data, leading to significant improvements in customer satisfaction and NPS. Actively collaborate with overseas teams in Germany and across India, fostering a global network of expertise and knowledge exchange while working under Agile Software development practices.	Data Science Associate	ZS · Full-time	https://media.licdn.com/dms/image/v2/C510BAQFA5PVsyW0KzQ/company-logo_100_100/company-logo_100_100/0/1631428390966/ketiot_logo?e=1759363200&v=beta&t=qTZqXv4TIip4TpZ7fRa4HQqPp3ep139CjvqmUSgjKGU	Dec 2020 to Oct 2022 · 1 yr 11 mos	Delta Air Lines · Full-time	Bengaluru, Karnataka, India · Hybrid	Causal Inference, Data Science and +3 skills	https://www.linkedin.com/company/1593/	Data Scientist	Deutsche Telekom · Full-time	Oct 2022 - Jun 2024 · 1 yr 9 mos	https://www.linkedin.com/in/ajha16/overlay/urn:li:fsd_profilePosition:(ACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg,2048654271)/skill-associations-details?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg	Data Architecture, Causal Inference and +10 skills	https://www.linkedin.com/company/5240/	https://www.linkedin.com/company/5240/	Bangalore Urban, Karnataka, India	https://www.linkedin.com/in/ajha16/details/experience?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg	Show all 7 experiences		
			Education	Embarked on a journey of innovation and entrepreneurship by spearheading the development of an AI-powered digital security assistant and actively participating in hackathons and AI events, showcasing my technical prowess and entrepreneurial spirit.	Indian Institute of Technology, Patna	Indian Institute of Technology, Patna	Master of Technology - MTech, Artificial Intelligence		Feb 2023 - Jul 2025	https://www.linkedin.com/company/893253/	https://www.linkedin.com/company/893253/	https://media.licdn.com/dms/image/v2/C4E0BAQGH4kZC3mionA/company-logo_100_100/company-logo_100_100/0/1631346744079?e=1759363200&v=beta&t=CisNO8Kqdw6D11QfJUJ8MxbTUVABrbGGJUMKNlrDeKk	2016 - 2020			https://www.linkedin.com/search/results/all/?keywords=Institute+of+Technical+Eductaion+and+Research+			Institute of Technical Eductaion and Research		Bachelor of Technology - BTech, Computer Science Engineering			Feb 2023 - Jul 2025				Embarked on a journey of innovation and entrepreneurship by spearheading the development of an AI-powered digital security assistant and actively participating in hackathons and AI events, showcasing my technical prowess and entrepreneurial spirit.					Master of Technology - MTech, Artificial Intelligence			https://www.linkedin.com/search/results/all/?keywords=Institute+of+Technical+Eductaion+and+Research+	Institute of Technical Eductaion and Research	Bachelor of Technology - BTech, Computer Science Engineering	2016 - 2020						https://www.linkedin.com/in/ajha16/details/education?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg	Show all 3 educations		
			Licenses & certifications		Deeo Learning A-Z	Deeo Learning A-Z	Udemy		Issued Dec 2020	https://www.linkedin.com/company/822535/	https://www.udemy.com/certificate/UC-dd5602b3-a320-473b-8c1b-02ecf3d4c198/	https://media.licdn.com/dms/image/v2/D560BAQEf_NHzN2yVQg/company-logo_100_100/company-logo_100_100/0/1723593046388/udemy_logo?e=1759363200&v=beta&t=Ub7lkjyV4CwWFc80jqubCjfPWN99DyGesXZtN4WWWMk	Credential ID UC-dd5602b3-a320-473b-8c1b-02ecf3d4c198	https://www.linkedin.com/in/ajha16/overlay/urn:li:fsd_profileCertification:(ACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg,285885140)/skill-associations-details?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg		https://www.linkedin.com/company/822535/	https://media.licdn.com/dms/image/v2/D560BAQEf_NHzN2yVQg/company-logo_100_100/company-logo_100_100/0/1723593046388/udemy_logo?e=1759363200&v=beta&t=Ub7lkjyV4CwWFc80jqubCjfPWN99DyGesXZtN4WWWMk		Machine Learning A-Z: AI, Python & R		Udemy		Issued Jan 2019	Issued Dec 2020								Credential ID UC-99b43aed-11cd-4dea-a9cf-9cb07ee7e71b	Udemy	Credential ID UC-dd5602b3-a320-473b-8c1b-02ecf3d4c198	Artificial Neural Networks, Long Short-term Memory (LSTM) and +4 skills	https://www.udemy.com/certificate/UC-99b43aed-11cd-4dea-a9cf-9cb07ee7e71b/	Machine Learning A-Z: AI, Python & R	Udemy	Issued Jan 2019	https://www.linkedin.com/in/ajha16/overlay/urn:li:fsd_profileCertification:(ACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg,285470464)/skill-associations-details?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg	Classification, Statistics and +3 skills	https://www.udemy.com/certificate/UC-dd5602b3-a320-473b-8c1b-02ecf3d4c198/	https://www.udemy.com/certificate/UC-99b43aed-11cd-4dea-a9cf-9cb07ee7e71b/	Credential ID UC-99b43aed-11cd-4dea-a9cf-9cb07ee7e71b		Show credential		
			Skills	2 experiences across ZS and 1 other company	Object-Oriented Programming (OOP)	Object-Oriented Programming (OOP)	2 experiences across ZS and 1 other company		7 endorsements	https://www.linkedin.com/in/ajha16/overlay/urn:li:fsd_skill:(ACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg,290282232)/skill-insights?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg&tabIndex=0&modalTabIndex=0	https://www.linkedin.com/search/results/all/?keywords=Object-Oriented+Programming+%28OOP%29&origin=PROFILE_PAGE_SKILL_NAVIGATION	https://media.licdn.com/dms/image/v2/D560BAQHMSLJpNZSfhQ/company-logo_100_100/B56Zh6qM2lHMAU-/0/1754404540294/zs_associates_logo?e=1759363200&v=beta&t=f40UBPoW5XMxtyHvcHlu8MR0pb0rOsXX1Lm0TvpgC54	Data Science Associate at ZS	https://www.linkedin.com/in/ajha16/details/skills/urn:li:fsd_skill:(ACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg,290282232)/endorsers?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg&tabIndex=0&modalTabIndex=0&detailScreenTabIndex=0			https://media.licdn.com/dms/image/v2/D560BAQHMSLJpNZSfhQ/company-logo_100_100/B56Zh6qM2lHMAU-/0/1754404540294/zs_associates_logo?e=1759363200&v=beta&t=f40UBPoW5XMxtyHvcHlu8MR0pb0rOsXX1Lm0TvpgC54	Data Science Associate at ZS	Amazon Redshift																	https://www.linkedin.com/search/results/all/?keywords=Amazon+Redshift&origin=PROFILE_PAGE_SKILL_NAVIGATION	Amazon Redshift								https://www.linkedin.com/in/ajha16/details/skills?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg	Show all 32 skills		
			Recommendations	Ankit is an open-minded and a continuous learner. He picks up things faster and focuses deep to produce a result within less time. His passion for new technologies makes him apart from other fellows of his age group. If you are looking for a real geek to solve some of the complex technical problems, he can surely help you. I see a bright future for him.	Received	Ashish Singh	Given	Vivekanand Prasad	Ashish Singh	https://www.linkedin.com/in/ashishbyte	https://www.linkedin.com/in/ashishbyte	https://media.licdn.com/dms/image/v2/C4E03AQFooxMqNSKtTw/profile-displayphoto-shrink_100_100/profile-displayphoto-shrink_100_100/0/1517730344088?e=1759363200&v=beta&t=8mEt7KqREJSp2bRw5BPvzkfpAK8_1_EmVbVtK6iW2Gg	Software Engineer & Entrepreneur	https://www.linkedin.com/in/vivekannandprasad	July 2, 2018, Ashish was Ankit’s mentor	https://www.linkedin.com/in/vivekannandprasad	https://media.licdn.com/dms/image/v2/D4D03AQGLFb5QuOE8Kg/profile-displayphoto-shrink_100_100/profile-displayphoto-shrink_100_100/0/1722077238524?e=1759363200&v=beta&t=Y90vX9xGhUCRoRAeKoRltrNvrINN2N6pWseBVkAxOU8	"Ankit is one of the finest and smartest guy with having key skills and knowledge in the field of cyber-security that I have ever met. He is young, he is innovative, he is hardworking, and the most important one, he is a humble person. 
With having a number of awards like ""World Records India"" and dozens more, un-matched public speaking skills at such a young age, he is the most dynamic guy that I know in his age."	Ankit is an open-minded and a continuous learner. He picks up things faster and focuses deep to produce a result within less time. His passion for new technologies makes him apart from other fellows of his age group. If you are looking for a real geek to solve some of the complex technical problems, he can surely help you. I see a bright future for him.		Vivekanand Prasad		Educationist || Roboticist || On a mission to change the way we used to learn || Open for discussions about hardware startups/ideas || Mentor	July 2, 2018, Ashish was Ankit’s mentor			September 29, 2017, Vivekanand worked with Ankit but they were at different companies	"Ankit is one of the finest and smartest guy with having key skills and knowledge in the field of cyber-security that I have ever met. He is young, he is innovative, he is hardworking, and the most important one, he is a humble person. With having a number of awards like ""World Records India"" and dozens more, un-matched public speaking skills at such a young age, he is the most dynamic guy that I know in his age."					Software Engineer & Entrepreneur	Educationist || Roboticist || On a mission to change the way we used to learn || Open for discussions about hardware startups/ideas || Mentor					September 29, 2017, Vivekanand worked with Ankit but they were at different companies								Received	Given
			Languages		English	English	Full professional proficiency	Hindi	Hindi				Native or bilingual proficiency											Full professional proficiency															Native or bilingual proficiency									
	Follow	Follow	Interests		Top Voices	Lex Fridman	Companies	James Caan CBE	Groups	https://www.linkedin.com/in/lexfridman	https://www.linkedin.com/in/lexfridman	https://media.licdn.com/dms/image/v2/C4E03AQHLCrHhGZ0xMg/profile-displayphoto-shrink_100_100/profile-displayphoto-shrink_100_100/0/1519486751903?e=1759363200&v=beta&t=hcpYe1F8_2V0bjjqNOU6nD0Y8XhmU9YTyDToYe0qJgI	Newsletters	https://www.linkedin.com/in/jamescaancbe	Schools	https://www.linkedin.com/in/jamescaancbe	https://media.licdn.com/dms/image/v2/D4D03AQG95T103X3I3g/profile-displayphoto-scale_100_100/B4DZh5SvCxH8Ac-/0/1754381612570?e=1759363200&v=beta&t=7vThPOj4fA9duCFw5rt_V33W65StHjrh-M4KuFSGqLQ		Lex Fridman		Research Scientist, MIT		1,719,169 followers	1,719,169 followers			James Caan CBE	Hamilton Bradshaw | Serial Entrepreneur | Investor on BBC's Dragons’ Den (2007-2010)	3,291,946 followers				Research Scientist, MIT	Hamilton Bradshaw | Serial Entrepreneur | Investor on BBC's Dragons’ Den (2007-2010)		https://www.linkedin.com/in/ajha16/details/interests?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAB2ZgAQB9Od01zqfTktY-Z7X7PktVE-B2Hg&tabIndex=0&detailScreenTabIndex=0			3,291,946 followers							Show all Top Voices	Top Voices	Companies